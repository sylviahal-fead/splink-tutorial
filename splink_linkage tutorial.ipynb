{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linking without duplication\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splink steps:\n",
    "\n",
    "1) Prepare data\n",
    "2) Exploratory analysis \n",
    "3) Blocking:\n",
    "    - Create your blocking rules for prediction\n",
    "4) Estimate model parameters:\n",
    "    - Define comparisons\n",
    "    - Define your model using the link type, the comparisons and your blocking rules\n",
    "    - Estimate the parameters of the model and visualise to see what the model is doing\n",
    "5) Predict results\n",
    "    - Generate match_weight and match_probability scores\n",
    "    - Assign records to clusters \n",
    "6) Visualise predictions to see what the model is doing\n",
    "7) Evaluate against labelled data (if poss!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prerequisites\n",
    "\n",
    "Unique IDs:\n",
    "- Each input dataset must have a unique ID column (unique within the dataset)\n",
    "- By default, Splink assumes this will be called unique_id, but this can be changed\n",
    "\n",
    "Conformant datasets:\n",
    "- If using multiple datasets, they must share the same column names and data formats (order doesn't matter)\n",
    "\n",
    "Cleaning:\n",
    "- Ensure consistency by cleaning the data, e.g. standardising date formats, matching text case, handling invalid data\n",
    "- Usual data cleaning of obvious errors\n",
    "\n",
    "Ensure nulls are consistently and correctly represented:\n",
    "- Make sure that nulls are represented as true nulls, not empty strings - splink handles these types of value differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import splink #https://moj-analytical-services.github.io/splink/\n",
    "\n",
    "from splink.internals.duckdb.database_api import DuckDBAPI\n",
    "#splink implements data linking computations by generating SQL and submitting the SQL statements to a backend of our choice\n",
    "#syntax is almost exactly the same between backends \n",
    "#worth using DuckDB first to explore data as it is fast, then migrate to a different backend if desired\n",
    "\n",
    "from splink import block_on\n",
    "from splink import Linker, SettingsCreator\n",
    "\n",
    "from splink.datasets import splink_datasets #some datasets available with splink for practice https://moj-analytical-services.github.io/splink/api_docs/datasets.html\n",
    "from splink.exploratory import completeness_chart #https://moj-analytical-services.github.io/splink/api_docs/exploratory.html\n",
    "from splink.exploratory import profile_columns\n",
    "\n",
    "\n",
    "from splink.blocking_analysis import cumulative_comparisons_to_be_scored_from_blocking_rules_chart #https://moj-analytical-services.github.io/splink/api_docs/blocking_analysis.html\n",
    "from splink.blocking_analysis import count_comparisons_from_blocking_rule\n",
    "\n",
    "import splink.comparison_library as cl #https://moj-analytical-services.github.io/splink/api_docs/comparison_library.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prerequisites\n",
    "\n",
    "Unique IDs:\n",
    "- Each input dataset must have a unique ID column (unique within the dataset)\n",
    "- By default, Splink assumes this will be called unique_id, but this can be changed\n",
    "\n",
    "Conformant datasets:\n",
    "- If using multiple datasets, they must share the same column names and data formats (order doesn't matter)\n",
    "\n",
    "Cleaning:\n",
    "- Ensure consistency by cleaning the data, e.g. standardising date formats, matching text case, handling invalid data\n",
    "- Usual data cleaning of obvious errors\n",
    "\n",
    "Ensure nulls are consistently and correctly represented:\n",
    "- Make sure that nulls are represented as true nulls, not empty strings - splink handles these types of value differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df = splink_datasets.fake_1000\n",
    "df = df.drop(columns = [\"cluster\"])\n",
    "#split dataset into two\n",
    "df1 = df.sample(frac = 0.5)\n",
    "df2 = df.drop(df1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory analysis\n",
    "\n",
    "- Splink has a range of visuals to help with EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse nulls - columns with higher numbers of nulls are less useful for data linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_chart(\n",
    "    [df1, df2],\n",
    "    cols = [\"first_name\", \"surname\", \"dob\", \"city\", \"email\"],\n",
    "    db_api=DuckDBAPI(),\n",
    "    table_names_for_chart=[\"df_left\", \"df_right\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The completeness chart shows us the % of nulls in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess distribution of values\n",
    "- Columns with higher cardinality (number of distinct values) are more useful for linking\n",
    "- Columns that are more equally distributed are more useful for linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile_columns\n",
    "#dist plot showing the count of values at each percentile\n",
    "#top n chart showing the counc of the top n values within column\n",
    "#bottom n chart showing the count of the bottom n values in the column\n",
    "profile_columns([df1, df2], db_api = DuckDBAPI(), top_n = 10, bottom_n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Blocking\n",
    "\n",
    "Choosing blocking rules to optimise runtime\n",
    "- To link records, we need to compare pairs of records and decide which pairs are matches\n",
    "- For most large datasets, it won't be computationally possible to compare every row with every other row (the number of comparisons rises quadratically with the number of records)\n",
    "- To decide which ones to compare we use blocking rules - these specify which pairwise comparisons to generate\n",
    "- These are defined as SQL expressions, e.g.:\n",
    "\n",
    "    from splink import block_on\n",
    "    block_on(\"first_name\", \"surname\")\n",
    "\n",
    "    =\n",
    "    \n",
    "    SELECT *\n",
    "    FROM input_tables as l\n",
    "    INNER JOIN input_tables as r\n",
    "    on l.first_name = r.first_name AND l.surname = r.surname\n",
    "\n",
    "\n",
    "The aim of blocking rules are:\n",
    "- Eliminate enough non-matching comparison pairs so the we can computationally handle the number of pairwise comparisons\n",
    "- Eliminate as few true matching pairs as possible\n",
    "- Splink has some tools to help us choose effective rules\n",
    "- Lots of strict blocking rules are usually better than few loose rules; individually strict blocking rules are likely to exclude lots of true matches, multiple strict rules will make it implausible that a truly matching record gets missed, e.g.:\n",
    "    block_on(\"first_name\", \"dob\")\n",
    "    will retain all matching pairs except those with errors or nulls in the first name or dob fields\n",
    "    and\n",
    "    block_on(\"email\")\n",
    "    will retain all matching pairs except those with errors or nulls in the email column\n",
    "- Individually we would probably miss true matches where the records contain typos but between them, it's unlikely that the same records would have typos in both fields\n",
    "- If we add more strict blocking rules it becomes less likely that a record would get through the cracks here\n",
    "- Choosing good blocking rules is important to building a good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting comparisons created by a single rule\n",
    "#this is a good idea so we know that we are not generating too many records and wasting time computing them\n",
    "\n",
    "br = block_on(\"first_name\") #inital of first name and surname match\n",
    "counts = count_comparisons_from_blocking_rule(\n",
    "    table_or_tables=[df1, df2],\n",
    "    blocking_rule=br,\n",
    "    link_type=\"link_only\",\n",
    "    db_api= DuckDBAPI()\n",
    ")\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting comparisons created by a single rule\n",
    "#this is a good idea so we know that we are not generating too many records and wasting time computing them\n",
    "\n",
    "br = block_on(\"surname\") #inital of first name and surname match\n",
    "counts = count_comparisons_from_blocking_rule(\n",
    "    table_or_tables=[df1, df2],\n",
    "    blocking_rule=br,\n",
    "    link_type=\"link_only\",\n",
    "    db_api= DuckDBAPI()\n",
    ")\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting the number of comparisons created by a list of blocking rules\n",
    "blocking_rules_for_analysis = [\n",
    "        block_on(\"first_name\"),\n",
    "        block_on(\"surname\")\n",
    "]\n",
    "\n",
    "#cumulative_comparisons_to_be_scored_from_blocking_rules_chart(table_or_tbles, blocking_rules, link_type, db_api, unique_id_column_name = \"unique_id\", \n",
    "#max_rows_limit = int(1000000000.0), source_dataset_column_name = None)\n",
    "cumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n",
    "    table_or_tables=[df1, df2],\n",
    "    blocking_rules=blocking_rules_for_analysis,\n",
    "    db_api = DuckDBAPI(),\n",
    "    link_type=\"link_only\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and estimating the model\n",
    "- Estimating the model will help us understand the relative importance of different parts of the data for data linking\n",
    "- The relative importance is captured in the partial match weights (which are added to compute the overall match score)\n",
    "- To build a model, we define the partial match weights that splink is to estimate by defining how the data in the records should be compared\n",
    "- Comparisons represent how data from one or more input columns is compared\n",
    "- A model is composed of many Comparisons, which between them assess the similarity of all the columns being used for linking the data\n",
    "- Each comparison contains two or more ComparisonLevels which define n discrete graduations of similarity between input columns within the Comparison\n",
    "- Splink has a library of comparison functions which are split into:\n",
    "    - generic comparison functions which apply a particular fuzzy matching pattern (e.g. levenshtein distance)\n",
    "    - tailored comparison functions for specific data types\n",
    "\n",
    "- There are 3 ways of specifying comparisons:\n",
    "    - Using \"out-of-the-box\" Comparisons\n",
    "    - Composing pre-defined ComparisonLevels\n",
    "    - Writing a full dictionary spec of a Comparison by hand\n",
    "\n",
    "- \"Out-of-the-box\" Comparisons:\n",
    "    - The ComparisonLibrary has pre-baked similarity functions that cover many common use cases\n",
    "    - These functions generate an entire Comparison, composed of ComparisonLevels\n",
    "    - Include non-data-specific and data-specific comparisons\n",
    "\n",
    "- Composing pre-defined ComparisonLevels\n",
    "    - Compose our own Comparisons\n",
    "\n",
    "- Full dictionary spec\n",
    "    - All Comparisons are eventually turned into a dictionary\n",
    "    - The library functions are convenience functions that provide a shorthand way to produce valid dictionaries, but we can specify our own Comparisons directly as a dictionary to get maximum control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = SettingsCreator(\n",
    "    link_type=\"link_only\",\n",
    "    blocking_rules_to_generate_predictions=[\n",
    "        block_on(\"first_name\"),\n",
    "        block_on(\"surname\")\n",
    "    ],\n",
    "    comparisons=[\n",
    "        cl.NameComparison(\"first_name\"),\n",
    "        cl.NameComparison(\"surname\"),\n",
    "        cl.DateOfBirthComparison(\"dob\",\n",
    "            input_is_string = True,\n",
    "            invalid_dates_as_null = True\n",
    "        ),\n",
    "        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n",
    "        cl.EmailComparison(\"email\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "linker = Linker(\n",
    "    [df1, df2],\n",
    "    settings,\n",
    "    db_api = DuckDBAPI(),\n",
    "    input_table_aliases=[\"df_left\", \"df_right\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term frquency adjustments\n",
    "- The Fellegi-Sunter model doesn't account for skew in the distributions of linking variables\n",
    "- Consider, for example, a binary gender variable were males outnumber females by 10:1\n",
    "- This doesn't affect the m probability - given that two records are a match, the gender fields should match with roughly the same probability for males and females\n",
    "- The u probability, however is affected - given that two records are not a match, it is much more likely that both records will be male than that they will both be female - u probability is too low for the more common value and too high otherwise\n",
    "- One option might be to create different comparison levels for the gender variable, but this means we have to calculate more probabilities, and we would need many comparison levels if we had higher cardinality values\n",
    "- To deal with the problem we can add an independent TF adjustment term for each comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating lambda\n",
    "- ùúÜ = Pr(Records match) = probability that two records match\n",
    "- In some cases we might know lambda, for example, if we know that there is a one-to-one match between datasets\n",
    "- In most cases we don't know this, so we combine a set of deterministic matching rules and a guess of the recall corresponding to these rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic_rules = [\n",
    "    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.surname = r.surname and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) <= 2\",\n",
    "    block_on(\"email\"),\n",
    "]\n",
    "\n",
    "linker.training.estimate_probability_two_random_records_match(deterministic_rules, recall = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating m and u probabilities\n",
    "\n",
    "- m and u probabilities quantify the strength of the evidence we have in our data \n",
    "- m = Pr(scenario|records match)\n",
    "- u - Pr(scenario|records do not match)\n",
    "- What is important is the relative size of these values - this is the Bayes Factor:\n",
    "        K = m/u = Pr(scenario|records match)/Pr(scenario|records do not match)\n",
    "- Bayes Factors act as a relative multiplier that increases or decreases the overall prediction of whether the records match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating u probabilities\n",
    "- Once we have lambda, we can estimate u probabilities\n",
    "- We use the estimate_u_using_random_sampling method which samples random pairs of records, since most random pairs will be non-matches\n",
    "- Over these non-matches we compute the distribution of ComparisonLevels for each Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.training.estimate_u_using_random_sampling(max_pairs=1e8, seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We now need to estimate m - for this we have to have some idea of what the true matches are\n",
    "- We can use an iterative maximum likelihood approach called Expectation Maximisation:\n",
    "    - Iterative optimisation method that finds maximum likelihood of parameters in models that have unobserved latent variables (unobserved variables in models that can only be inferred indirectly through their effects on observed variables)\n",
    "    - Made up of an estimation (E) step and maximisation (M) step:\n",
    "        - E- compute the latent variables (expectation of the log-likelihood (log of likelihood function, which measures the goodness of fir between data nd the model) using the current parameter estimates)\n",
    "        - M- determine the parameters that maixmise the expected log-likelihood obtained in E step, and update the model paremeters based on the estimated latent variables\n",
    "- This estimates the m values by generating pairwise record comparisons and using them to maximise a likelihood function\n",
    "- Each estimation pass requires us to configure an estimation blocking rule to reduce the number of record comparisons so it is manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dob = linker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\n",
    "session_email = linker.training.estimate_parameters_using_expectation_maximisation(block_on(\"email\"))\n",
    "session_first_name = linker.training.estimate_parameters_using_expectation_maximisation(block_on(\"first_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can visualise the model parameters\n",
    "#see the final estimated match weights\n",
    "linker.visualisations.match_weights_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The match weights chart shows results of a trained Splink model\n",
    "- Each comparison is represented in a bar chart - eahc bar shows evidence for two records being a match for each comparison level\n",
    "- The first bar is our prior - bayesian prior - represents our belief that two random records will be a match\n",
    "\n",
    "Things to focus on:\n",
    "\n",
    "Match weights should gradually reduce within a comparison:\n",
    "- Comparison levels are order-dependent - so the most similar levels come first and the levels get gradually less similar\n",
    "- So we would expect that the match weight will reduce as we move down the levels\n",
    "\n",
    "We might want to combine comparison levels that are very similar\n",
    "- Comparisons are broken up into levels to show different levels of similarity\n",
    "- Because of this, we expect the amount of evidence (match weight) to vary between comparison levels\n",
    "- Two levels with the same match weight do not provide the model with any additional information, so we should combine very similar levels into a similar level\n",
    "\n",
    "We might want to simplify a model that has a number of highly predictive features\n",
    "- Where we have a large variation between comparison levels, it indicates that we have a highly predictive feature (consider the difference between and exact match on email and all other comparisons on email)\n",
    "- If we have a lot of highly predictive features, we might consider simplifying the model using the more predictive features\n",
    "\n",
    "Logically walk through each comparison level\n",
    "- Check the amount of evidence (match weight) that has been allocated by the model for each comparison level\n",
    "- Logically consider each level and how much evidence matches give us - do they make sense knowing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m and u values\n",
    "linker.visualisations.m_u_parameters_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Left shows estimated m probabilities - the probability of a given comparison level when two records are a match - the proportion of matching records allocated to the comparison level\n",
    "- Right shows estimated u probabilities - the probability of a given comparison level when two records do not match - the proportion of non-matching records allocated to the comparison level\n",
    "\n",
    "Things to focus on:\n",
    "\n",
    "Logically walk through each comparison level\n",
    "- Consider, for example, how often exact matches and fuzzy levels occurence in non-matching comparisons\n",
    "- Consider the cardinality of the features - high cardinality features will generally have lower likelihood of \"all other comparisons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparisons\n",
    "linker.visualisations.parameter_estimate_comparisons_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shows how parameter estimates have differed across different estimation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting match weights\n",
    "- Linker.predict() runs the model\n",
    "- This generates all pariwise record comparisons that match at least one of the blocking_rules_to_generate_predictions\n",
    "- Uses the rules we defined in the comparisons to evaluate the similarity of the input data\n",
    "- Uses the estimated match weights, applying term frequency adjustments where we have set this as true, to produce the final_match_weight and match_probability scores\n",
    "- We can also define a threshold_match_probability or theshold_match_Weight to drop any rows where the predicted score is below a certain threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes Factors -> probabilities\n",
    "\n",
    "- The prior is our existing belief that two random records match (our belief of the scenario before we have any evidence)\n",
    "- The posterior is our belief that two records match given the evidence we have (the data we have about the records)\n",
    "\n",
    "- Mathematically:\n",
    "\n",
    "    posterior odds = prior odds * Bayes Factor\n",
    "\n",
    "- And Bayes Theorem is:\n",
    "\n",
    "    Pr(a|b) = Pr(b|a) * Pr(a) / Pr(b)\n",
    "\n",
    "- or:\n",
    "\n",
    "    posterior probability = likelihood * prior probability / evidence\n",
    "\n",
    "- so if we consider one column (e.g. first name):\n",
    "\n",
    "    Pr(match|first name matches) = Pr(first name matches|match) * Pr(match) / Pr(first name matches)\n",
    "\n",
    "- which we can also write as:\n",
    "\n",
    "    Pr(match|first name matches) = Pr(first name matches|match) * Pr(match) / Pr(first name matches|match) * Pr(match) + Pr(first name matches|non match) * Pr(non match)\n",
    "\n",
    "- m = Pr(scenario|records match)\n",
    "- u - Pr(scenario|records do not match)\n",
    "\n",
    "- so this is the same as:\n",
    "\n",
    "    posterior probability = m * prior probability / m * prior probability + u * (1 - prior probability)\n",
    "\n",
    "- Odds is:\n",
    "\n",
    "    odds = p / 1-p\n",
    "\n",
    "- so:\n",
    "\n",
    "    posterior odds = prior / 1 - prior  m / u\n",
    "\n",
    "- so for a specific scenario:\n",
    "\n",
    "    posterior odds = prior odds * Bayes Factor\n",
    "\n",
    "- This formula can account for data in multiple scenarios (e.g. a match in on multiple parameters, or a match on some and not on others) (Naive Bayes classifier):\n",
    "\n",
    "    posterior odds = prior odds * Bayes Factor 1 * Bayes Factor 2 ... * Bayes Factor n\n",
    "\n",
    "- Which means:\n",
    "    posterior odds = prior odds * m1 m2 ... mn / u1 u2 ... un\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = linker.inference.predict(threshold_match_probability = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.as_pandas_dataframe(limit = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering records\n",
    "- From the linker.predict we get a list of pairwise record comparisons and their scores\n",
    "- We now need to convert the pairwise results into clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n",
    "    results, threshold_match_probability=0.5\n",
    ")\n",
    "clusters.as_pandas_dataframe(limit = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "select *\n",
    "from {results.physical_name}\n",
    "limit 2\n",
    "\"\"\"\n",
    "\n",
    "linker.misc.query_sql(sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
